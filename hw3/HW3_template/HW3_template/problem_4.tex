 In the textbook, language modeling was defined as the task of predicting the next word in a sequence given the previous words. In this assignment, you will implement character-level, word-level N-gram  and character-level RNN language models. You need to both answer the questions and submit your code. You need to submit a zip file to Canvas Homework 3 Programming. This file should contain \texttt{ngram.ipynb}, \texttt{rnn.ipynb} \texttt{hw3\_skeleton\_char.py} and \texttt{hw3\_skeleton\_word.py}. 
 
 You should also submit a zip file to the Gradescope assignment HW3 Language Models. 
 This file should contain \texttt{hw3\_skeleton\_char.py} and \texttt{hw3\_skeleton\_word.py}.

\begin{enumerate}
    \item For N-gram language models, You should complete two scripts \texttt{hw3\_skeleton\_char.py} and \texttt{hw3\_skeleton\_word.py}. Detailed instructions can be found in  \href{https://www.cc.gatech.edu/classes/AY2020/cs7650_spring/hw3/lm/ngram.zip} {\texttt{ngram.ipynb}}. You should also use test cases in \texttt{ngram.ipynb} and use \texttt{ngram.ipynb} to get development results for (c). 
    
    You need to submit a zip file to Gradescope HW3 Language Models. This file should contain \texttt{hw3\_skeleton\_char.py} and \texttt{hw3\_skeleton\_word.py}. You can see the scores for your code there. Character-level N-gram language models accounts for 20 points. Word-level N-gram language models accounts for 10 points, which are bonus for CS 4650. [30pts for CS 7650, 20 pts + bonus 10pts for CS 4650] 

     
    \item See the generation results of your character-level and word-level N-gram language models respectively ($n\geq 1$). The paragraphs which character-level N-gram language models generate all start with \textit{F}. The paragraphs which word-level N-gram language models generate all start with \textit{In}. Did you get such results? Explain what is going on. (CS 4650 can only focus on character-level N-gram language model.) [2 pts]
    
    
    \item (Bonus for CS 4650) Compare the generation results of character-level and word-level N-gram language models. Which do you think is better?  Compare the perplexity of \texttt{shakespeare\_sonnets.txt} when using character-level and word-level N-gram language models. Explain what you found. [2pts, bonus for CS 4650]
    
    \item When you compute perplexity, you can play with different sets of hyper-parameters in both character-level and word-level N-gram language models. You can tune $n$ , $k$ and $\lambda$. Please report here the best results and the corresponding hyper-parameters in development sets. For character-level N-gram language models, the development set is \texttt{shakespeare\_sonnets.txt}. For word-level N-gram language models, the development sets are \texttt{shakespeare\_sonnets.txt} and \texttt{val\_e.txt}. (CS 4650 should only focus on character-level N-gram language model.) [6 pts for CS 7650, 2 pts + bonus 4 pts for CS 4650]
    
    \item For RNN language models, You should complete the forward method of Class RNN in  \href{https://www.cc.gatech.edu/classes/AY2020/cs7650_spring/hw3/lm/rnn.zip} {\texttt{rnn.ipynb}}. You need to figure out the code and tune the hyperparameters. You should also copy a paragraph generated by your model and report the perplexity on the development set \texttt{shakespeare\_sonnets.txt}. Compare the results of character-level RNN language model and character-level N-gram language model. [10 pts]

\end{enumerate}


\begin{solution} \ \\
Solution goes here.
\end{solution}
